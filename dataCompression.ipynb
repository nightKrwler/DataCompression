{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burrows-Wheeler-Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "table done\ndone\n"
    }
   ],
   "source": [
    "def bwt(s):\n",
    "    assert\"\\003\" not in s, \"Input string cannot contain ETX characters\"\n",
    "    s = s + \"\\003\"\n",
    "    table = sorted(s[i:] + s[:i] for i in range(len(s))) \n",
    "    print(\"table done\")\n",
    "    last_column = [row[-1:] for row in table]\n",
    "    return \"\".join(last_column)\n",
    "\n",
    "path = \"./repetitions_data.txt\"\n",
    "file1 = open(path,'r')\n",
    "data = file1.read()\n",
    "\n",
    "encoded_data = bwt(data)\n",
    "\n",
    "outpath = \"bwt.txt\"\n",
    "\n",
    "outfile = open(outpath,\"w\")\n",
    "outfile.write(encoded_data)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Length Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": ".435:\n1455:?80:\t39:!75:”45:k585:,695:s2780:o3510:y840:r2085:d1470:t2955:;100:n2215:e3955:35:010:110:-140:u1480: 9887:p775:*110:f710:l1860:m780::5:w860:–55:’85:h2085:g1070:I350:R30:—5:a2655:i2235:x80:q45:z125:A185:ó5:\"30:D25:P70:)5:520:“45:T165:O40:S140:﻿1:í5:V5:E10:b450:M35:c1455:F80:Y55:B80:j95:ñ30:C30:ú5:(5:v155:H80:W110:J15:K5:L5:G20:'155:N5:Ñ5:á10:è10:‘5:\u00031:\ndone\n"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def runLengthEncoding(input): \n",
    "    dict=OrderedDict.fromkeys(input, 0) \n",
    "    for ch in input: \n",
    "        dict[ch] += 1\n",
    "    output = '' \n",
    "    for key,value in dict.items(): \n",
    "         output = output + key + str(value)+ \":\" # for demarcation - Decompression\n",
    "    return output \n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    path = \"./bwt.txt\"\n",
    "    \n",
    "    file1 = open(path,'r')\n",
    "    data = file1.read()\n",
    "    input=data\n",
    "    output = runLengthEncoding(input) \n",
    "    print(output)\n",
    "    outpath = \"./bwt_rle.txt\"\n",
    "    outfile = open(outpath,\"w\")\n",
    "    outfile.write(output)\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lempel-Ziv Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "35263"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Lz77:\n",
    "    def __init__(self, sliding_window_size, search_buffer_size):\n",
    "        self.sws = sliding_window_size\n",
    "        self.sbs = search_buffer_size\n",
    "        self.encoded_text = \"\"\n",
    "        self.codes = []\n",
    "    \n",
    "    def compressor(self,data):\n",
    "        encoded_text  = \"\"\n",
    "        position = 0 \n",
    "        offset = 0\n",
    "        max_match_length = 0\n",
    "        while(position<len(data)):\n",
    "            #print(\"a\")\n",
    "            offset,max_match_length,codeword =  self.match(position,data)\n",
    "            self.codes.append([offset,max_match_length,codeword])\n",
    "            position += max_match_length+1\n",
    "            #print(\"c\", max_match_length)\n",
    "            encoded_text = encoded_text+str(offset)+\" \"+ str(max_match_length)+\" \"+codeword+\" \"\n",
    "        self.encoded_text = encoded_text\n",
    "        return encoded_text\n",
    "\n",
    "    def match(self, position, data):\n",
    "        sb = self.sbs\n",
    "        i = 1\n",
    "        key = data[position]\n",
    "        max_match_length = 0\n",
    "        offset = 0\n",
    "        while((position-i)>=0 and i!=sb+1):\n",
    "            #print(\"b\")\n",
    "            length = 0\n",
    "            if(data[position-i]==key):\n",
    "                length+=1\n",
    "                j = 1\n",
    "                while(position-i+j!= len(data) and position+j!=len(data)):\n",
    "                    if(data[position-i+j]== data[position+j]):\n",
    "                        length+=1\n",
    "                        j+=1\n",
    "                    else:\n",
    "                        break\n",
    "                if(max_match_length<length):\n",
    "                    max_match_length = length\n",
    "                    offset = i\n",
    "            i +=1\n",
    "            if(position+max_match_length==len(data)):\n",
    "                return offset,max_match_length,\"\"\n",
    "        return offset,max_match_length,data[position+max_match_length]\n",
    "\n",
    "    def decompressor(self):\n",
    "        decoded_text = \"\"\n",
    "        for code in (self.codes):\n",
    "            pointer_position = len(decoded_text)\n",
    "            offset = code[0]\n",
    "            length = code[1]\n",
    "            code_word = code[2]\n",
    "            for j in range(length):\n",
    "                decoded_text += decoded_text[pointer_position-offset+j] \n",
    "            decoded_text+=code_word\n",
    "\n",
    "        return decoded_text\n",
    "\n",
    "path = \"./binary_data/bwt.txt\"\n",
    "outpath = \"./bwt_lz77.txt\"\n",
    "outpath2 = \"./lz77_decompressed.txt\"\n",
    "file1 = open(path,'r')\n",
    "data = file1.read()\n",
    "sliding_window_size = 13\n",
    "search_buffer_size = 7\n",
    "lz = Lz77(sliding_window_size, search_buffer_size)\n",
    "compressed = lz.compressor(data)\n",
    "output_compressed = open(outpath,'w')\n",
    "output_compressed.write(compressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huffman Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Compressed Successfully\n"
    }
   ],
   "source": [
    "import heapq\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import re\n",
    "from functools import total_ordering\n",
    "\n",
    "@total_ordering\n",
    "class Node:\n",
    "    def __init__(self, freq,char):\n",
    "        self.left = None\n",
    "        self.right= None\n",
    "        self.fre = freq\n",
    "        self.key = char\n",
    "    \n",
    "    # defining comparators less_than and equals\n",
    "    def __lt__(self, other):\n",
    "        return self.fre < other.fre\n",
    "\n",
    "    def __eq__(self,other):\n",
    "        if(other == None):\n",
    "            return False\n",
    "        if(not isinstance(other , Node)):\n",
    "            return False\n",
    "        return self.fre == other.fre\n",
    "\n",
    "class Tree:\n",
    "    def __init__(self,listfreq):\n",
    "        self.heap = []\n",
    "        self.codes = {}\n",
    "        self.reverse_mapping = {}\n",
    "        for key in listfreq:\n",
    "            node = Node(listfreq[key], key)\n",
    "            heapq.heappush(self.heap,node)\n",
    "\n",
    "        while(len(self.heap)>1):\n",
    "            t1 = heapq.heappop(self.heap)\n",
    "            t2 = heapq.heappop(self.heap)\n",
    "            count = t1.fre + t2.fre\n",
    "            D = Node(count,None)\n",
    "            D.left = t1\n",
    "            D.right = t2\n",
    "            heapq.heappush(self.heap, D)\n",
    "\t\n",
    "    \n",
    "    def huffmancode(self, root, current_code):\n",
    "        if (root == None) :\n",
    "            return\n",
    "\n",
    "        if(root.key != None):\n",
    "            self.codes[root.key] = current_code\n",
    "            self.reverse_mapping[current_code] = root.key\n",
    "            return\n",
    "        \n",
    "        self.huffmancode(root.left,current_code+\"0\")\n",
    "        self.huffmancode(root.right, current_code+\"1\")\n",
    "\n",
    "    def encoded_te(self, text):\n",
    "        return  \"\".join(self.codes[let] for let in text)\n",
    "    def compress(self, text, output_path):\n",
    "        encoded_text =  \"\".join(self.codes[let] for let in text)\n",
    "        extra_padding = 8 - len(encoded_text)%8\n",
    "        for i in range(extra_padding):\n",
    "            encoded_text += \"0\"\n",
    "        \n",
    "        padded_count = \"{0:08b}\".format(extra_padding)\n",
    "\n",
    "        padded_encoded_text = padded_count + encoded_text\n",
    "\n",
    "        if(len(padded_encoded_text)%8 !=0):\n",
    "            print(\" Not padded properly\")\n",
    "            exit(0)\n",
    "\n",
    "        b = bytearray()\n",
    "\n",
    "        for i in range(0, len(padded_encoded_text), 8):\n",
    "            byte = padded_encoded_text[i:i+8]\n",
    "            b.append(int(byte,2))\n",
    "        \n",
    "    \n",
    "        output = open(output_path, 'ab')\n",
    "\n",
    "        output.write(bytes(b))\n",
    "        output.close()\n",
    "        print(\"Compressed Successfully\")\n",
    "        return output_path\n",
    "        \n",
    "\n",
    "def main():\n",
    "\n",
    "    path = \"./bwt_rle.txt\"\n",
    "    output_path = \"./bwt_rle_huffman.bin\"\n",
    "    file1 = open(path,'r')\n",
    "    data = file1.read()\n",
    "    res = Counter(data)\n",
    "    tree =  Tree(res)\n",
    "    root = heapq.heappop(tree.heap)\n",
    "    s = ''\n",
    "    tree.huffmancode(root,s)\n",
    "    #print(tree.codes)\n",
    "    compressed_path = tree.compress(data,output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Compressed Successfully\nb\nCompressed Successfully\nb\ndone\n"
    }
   ],
   "source": [
    "def deflate():\n",
    "    path = \"./test_data.txt\"\n",
    "    output_path = \"./entire40.bin\"\n",
    "    output_path2 = \"./deflate_compressed65.bin\"\n",
    "    file1 = open(path,'r')\n",
    "    data = file1.read()\n",
    "    block_size = 1024*65\n",
    "\n",
    "    sliding_window_size = 4096*4/3\n",
    "    search_buffer_size = sliding_window_size*3/4\n",
    "\n",
    "    lz = Lz77(sliding_window_size, search_buffer_size)\n",
    "    lz_compressed = lz.compressor(data)\n",
    "    \n",
    "    res = Counter(lz_compressed)\n",
    "    huffman_tree =  Tree(res)\n",
    "    root = heapq.heappop(huffman_tree.heap)\n",
    "    s = ''\n",
    "    huffman_tree.huffmancode(root,s)\n",
    "    \n",
    "    '''entire_array = bytearray()\n",
    "\n",
    "    entire_array = huffman_tree.compress(lz_compressed)\n",
    "\n",
    "    output = open(output_path, 'wb')\n",
    "\n",
    "    output.write(bytes(entire_array))\n",
    "\n",
    "    print(\"Compressed Successfully\")'''\n",
    "\n",
    "    #final = huffman_tree.compress(lz_compressed,output_path)\n",
    "    \n",
    "    i=0\n",
    "    encoded_text = ''\n",
    "    while(i<len(data)):\n",
    "        block_data = data[i:i+block_size]\n",
    "        i+= block_size\n",
    "\n",
    "        lz_block = Lz77(sliding_window_size, search_buffer_size)\n",
    "        lz_block_compressed = lz_block.compressor(block_data)\n",
    "\n",
    "        res_block = Counter(lz_block_compressed)\n",
    "        hblock_tree = Tree(res_block)\n",
    "        root_block = heapq.heappop(hblock_tree.heap)\n",
    "        s_block = ''\n",
    "        hblock_tree.huffmancode(root_block, s_block)\n",
    "        etext_block = hblock_tree.encoded_te(lz_block_compressed) \n",
    "        etext = huffman_tree.encoded_te(lz_block_compressed)\n",
    "\n",
    "        if( len(etext)<len(etext_block)) :\n",
    "            huffman_tree.compress(lz_block_compressed,output_path2)\n",
    "            print(\"a\")\n",
    "        else :\n",
    "            hblock_tree.compress(lz_block_compressed,output_path2)\n",
    "            print(\"b\")\n",
    "\n",
    "deflate()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.15-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}